{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c596534-549c-45c5-9084-c59739bf34a1",
   "metadata": {},
   "source": [
    "# This notebook is to prototype with loading CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140bda61-f485-4fff-b509-ab9a0a0a1187",
   "metadata": {},
   "source": [
    "## Launch EVA DB\n",
    "Run the command `python eva.py` in the server where you want to deploy EVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375f5a3-6f38-45ad-9c99-cb21321c2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "\n",
    "# eva lib\n",
    "sys.path.insert(0,'..')\n",
    "from src.server.db_api import connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c514adf-1f8a-4185-b276-03e5b00688c5",
   "metadata": {},
   "source": [
    "## Establish connection with EVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b9137-3397-4e9b-ab2c-d9af456a0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "connection = connect(host = '0.0.0.0', port = 5432) # hostname, port of the server where EVADB is running\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685dcc22-b964-4c77-a126-8e601e8e56c9",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17260df0-f3a3-4d75-aeb3-c2483c2e3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_all_meta_to_csv(dataset_name):\n",
    "    \"\"\"\n",
    "    Looks at the info folder of the given dataset. Converts each one of the json file into a csv file (in the required format)\n",
    "    and dumps it in the same folder. Currently supports only the format of BDD\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (string) - name of given dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    eva_root_folder = \"../\"\n",
    "    #dataset_name = \"bdd_test\"\n",
    "\n",
    "    # dataset_name must be your folder name\n",
    "    dataset_path = os.path.join(eva_root_folder, 'data', 'datasets', dataset_name)\n",
    "\n",
    "    print(f\"Loading {dataset_name} from the path {dataset_path}\")\n",
    "\n",
    "    # videos contains the raw videos\n",
    "    videos_path = os.path.join(dataset_path, 'videos')\n",
    "\n",
    "    # info contains a json file corresponding to each video\n",
    "    info_path = os.path.join(dataset_path, 'info')\n",
    "\n",
    "    # Load the paths for all videos and info files\n",
    "    video_files = [os.path.join(videos_path, f) for f in sorted(os.listdir(videos_path))]\n",
    "    info_files = [os.path.join(info_path, f) for f in sorted(os.listdir(info_path))]\n",
    "    \n",
    "    # convert each one of the meta json file to csv\n",
    "    dataset_len = len(video_files)\n",
    "    for i in range(dataset_len):\n",
    "        # total frames is required to map the frame id correctly\n",
    "        total_frames = cv2.VideoCapture(video_files[i]).get(7)\n",
    "        convert_json_to_csv(dataset_name, info_files[i], video_id=i, total_frames=total_frames, dump=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99f552-f699-496d-ad07-d3438bc27b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_meta_table(dataset_name):\n",
    "    \"\"\"\n",
    "    Creates a meta table for the given dataset\n",
    "    TODO: Make this function more flexible to receive column name, type etc..\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (string) - name of dataset\n",
    "        \n",
    "    Returns:\n",
    "        True/False depending on if table creation was successful or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    table_name = dataset_name + \"_meta\"\n",
    "    \n",
    "    # Make this query dynamic later\n",
    "    create_table_query = f\"\"\" \n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        id INTEGER UNIQUE,\n",
    "        frame_id INTEGER,\n",
    "        video_id INTEGER,\n",
    "        labels NDARRAY STR(ANYDIM),\n",
    "        bboxes NDARRAY FLOAT32(ANYDIM, 4),\n",
    "        object_ids NDARRAY FLOAT32(ANYDIM)\n",
    "    );\n",
    "\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    response = cursor.fetch_all()\n",
    "    \n",
    "    if response.status == '0':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23a752-bc42-49ff-86f4-2dec94cca8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_csv(dataset_name, info_path, video_id, total_frames, dump=False):\n",
    "    \"\"\"\n",
    "    Parses a given info json file into a csv and dumps it (optionally). \n",
    "    total_frames is required to know which entry in the json corresponds to which frame id of video\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (string) - name of the dataset this video belongs to. There should be table existing with this name\n",
    "        info_path (string) - path to the info file\n",
    "        video_id (int) - video id\n",
    "        total_frames (int) - total frames of the current video\n",
    "        dump (bool) - dumps the dataframe as a csv in the same destination\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"info_path: {info_path} total_frame: {total_frames}\")\n",
    "    info_file_name = info_path.split('/')[-1].split('.')[0]\n",
    "    info_folder_path = \"/\".join(info_path.split('/')[:-1])\n",
    "    \n",
    "    if os.path.exists(os.path.join(info_folder_path, info_file_name + \".csv\")):\n",
    "        print(f\"already converted to csv\")\n",
    "        return\n",
    "        \n",
    "    with open(info_path, 'rb') as json_file:\n",
    "        info_json = json.load(json_file)\n",
    "        \n",
    "    # number of frames for which we have information\n",
    "    num_frames_info = len(info_json)\n",
    "    \n",
    "    # we assume the entries in the frame info are equally spaced\n",
    "    # eg: if there are 100 total frames and 10 entries in info_json, then sample_frequency = 10 or we have info for \n",
    "    # every 10 frames\n",
    "    sample_frequency = total_frames / num_frames_info\n",
    "    \n",
    "    meta = {}\n",
    "    i = 0\n",
    "    \n",
    "    for info in info_json:\n",
    "        frame_index = int(info['frameIndex'])\n",
    "        frame_id = int(frame_index * sample_frequency)\n",
    "\n",
    "        for label in info['labels']:\n",
    "            object_label = label['category']\n",
    "            bbox = [[label['box2d']['x1'], label['box2d']['y1']], [label['box2d']['x2'], label['box2d']['y2']]]\n",
    "            object_id = label['id']\n",
    "            \n",
    "            meta[i] = {\n",
    "                \"frame_id\" : int(frame_id),\n",
    "                \"video_id\" : int(video_id),\n",
    "                \"dataset_name\" : dataset_name,\n",
    "                \"label\" : object_label,\n",
    "                \"bboxes\" : bbox,\n",
    "                \"object_id\" : object_id\n",
    "            }\n",
    "            i += 1\n",
    "                \n",
    "    meta_df = pd.DataFrame.from_dict(meta, \"index\")\n",
    "    \n",
    "    if dump:\n",
    "        print(f\"dumping in {info_folder_path}\")\n",
    "        meta_df.to_csv(os.path.join(info_folder_path, info_file_name + \".csv\"), index=False)\n",
    "        \n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1cc8e-8637-4076-98fd-ef252ae76002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(dataset_name, video_path, info_path):\n",
    "    \"\"\"\n",
    "    Takes the path to 1 video and its corresponding json file. \n",
    "    Iterates over each frame of the video and performs an INSERT operation on the table\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (string) - name of the dataset this video belongs to. There should be table existing with this name\n",
    "        video_path (string) - path of the video to be loaded\n",
    "        info_path (string) - path of the json file that contains info about the video\n",
    "    \"\"\"\n",
    "    \n",
    "    table_name = dataset_name + \"_meta\"\n",
    "    print(f\"Loading video from: {video_path} info from: {info_path} into {table_name}\")\n",
    "    \n",
    "    # load video\n",
    "    video_name_with_ext = video_path.split('/')[-1]\n",
    "    video_name = video_name_with_ext.split('.')[0]\n",
    "    upload_video_query = f'UPLOAD INFILE \"{video_path}\" PATH \"{video_name_with_ext}\";'\n",
    "    load_video_query = f'LOAD DATA INFILE \"{video_name_with_ext}\" INTO {video_name};'\n",
    "    \n",
    "    print(f\"upload_video_query: {upload_video_query}\")\n",
    "    print(f\"load_video_query: {load_video_query}\")\n",
    "    \n",
    "    # load meta\n",
    "    meta_name_with_ext = info_path.split('/')[-1]\n",
    "    meta_name = meta_name_with_ext.split('.')[0]\n",
    "    upload_meta_query = f'UPLOAD INFILE \"{info_path}\" PATH \"{meta_name_with_ext}\";'\n",
    "    load_meta_query = f'LOAD DATA INFILE \"{meta_name_with_ext}\" INTO {table_name};'\n",
    "    \n",
    "    print(f\"upload_meta_query: {upload_meta_query}\")\n",
    "    print(f\"load_meta_query: {load_meta_query}\")\n",
    "    \n",
    "    # TODO: Need to execute these queries after getting the csv_executor code working\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ba98b-7ed6-4058-92e2-9a4263b22192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name):\n",
    "    \"\"\"\n",
    "    A folder named dataset_name is expected to be inside datasets. This folder should contain 2 other folders named info and videos\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (string) - name of the dataset\n",
    "        \n",
    "    Returns:\n",
    "        True if all videos have been loaded succesfully\n",
    "        False if there was any error\n",
    "    \"\"\"\n",
    "    \n",
    "    eva_root_folder = \"../\"\n",
    "\n",
    "    # dataset_name must be your folder name\n",
    "    dataset_path = os.path.join(eva_root_folder, 'data', 'datasets', dataset_name)\n",
    "    print(f\"Loading {dataset_name} from the path {dataset_path}\")\n",
    "    \n",
    "    # first create a meta table for this dataset if it doesnt exist\n",
    "    if create_meta_table(dataset_name):\n",
    "        print(f\"Table created successfully for {dataset_name}\")\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    # Load the paths for all videos and info files\n",
    "    videos_path = os.path.join(dataset_path, 'videos')\n",
    "    info_path = os.path.join(dataset_path, 'info')\n",
    "    video_files = [os.path.join(videos_path, f) for f in sorted(os.listdir(videos_path))]\n",
    "    info_files = [os.path.join(info_path, f) for f in sorted(os.listdir(info_path))]\n",
    "    \n",
    "    # check that each video under videos has a corresponding meta file\n",
    "    for video_file in video_files:\n",
    "        video_name = video_file.split('/')[-1].split('.')[-2]\n",
    "        expected_info_file = os.path.join(dataset_path, 'info', video_name + '.csv')\n",
    "        if expected_info_file not in info_files:\n",
    "            print(f\"Each video under videos should have a corresponding info file under info.\")\n",
    "            return False\n",
    "            \n",
    "    # loop through each video and load them one by one\n",
    "    dataset_len = len(video_files)\n",
    "    for video_index in range(dataset_len):\n",
    "        video_path = video_files[video_index]\n",
    "        info_path = info_files[video_index]\n",
    "        \n",
    "        # load this video along with its meta info\n",
    "        load_video(dataset_name, video_path, info_path)\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f014f-b461-443a-888f-16aa6c10b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"bdd_test\"\n",
    "\n",
    "if load_dataset(dataset_name):\n",
    "    print(f\"Dataset loaded successfully!\")\n",
    "else:\n",
    "    print(f\"One or more video loads failed! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b23f0-db64-47df-bf18-8a9a9a54a0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08629e7-c47b-4346-8704-2070853359dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651bf6c3-3e60-44fa-adf7-ff0ca3fb9e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ad8f6-2c18-4fff-88ac-716256ef393d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eva",
   "language": "python",
   "name": "eva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
