{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12ed8d69-c695-48ad-b98a-9b3d098d760b",
   "metadata": {},
   "source": [
    "# This notebook is to demonstrate how to load datasets into EVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2abfa-445f-488d-9297-00ce0ed16c64",
   "metadata": {},
   "source": [
    "## Launch EVA DB\n",
    "Run the command `python eva.py` in the server where you want to deploy EVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68fb5924-f075-48a3-927b-46b9c796b99e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "\n",
    "# eva lib\n",
    "sys.path.insert(0,'..')\n",
    "from src.server.db_api import connect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e71b89-cac0-4e7b-8dba-4117a86e18d6",
   "metadata": {},
   "source": [
    "## Establish connection with EVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5323de-9145-45fd-a58e-27b067feaca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "connection = connect(host = '0.0.0.0', port = 5432) # hostname, port of the server where EVADB is running\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac526a62-3c6b-458f-8160-218457711491",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965ab7ec-7305-4b54-a6e2-aedbb8157c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(table_name):\n",
    "    \"\"\"\n",
    "    Creates a new table with table_name\n",
    "    TODO: Make this function more flexible to receive column name, type etc..\n",
    "    \n",
    "    Args:\n",
    "        table_name (string) - name of table\n",
    "        \n",
    "    Returns:\n",
    "        True/False depending on if table creation was successful or not.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make this query dynamic later\n",
    "    create_table_query = f\"\"\" \n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS BDD (\n",
    "        id INTEGER UNIQUE,\n",
    "        frame_id INTEGER,\n",
    "        video_id INTEGER,\n",
    "        frame_data NDARRAY UINT8(3, ANYDIM, ANYDIM),\n",
    "        labels NDARRAY STR(ANYDIM),\n",
    "        bboxes NDARRAY FLOAT32(ANYDIM, 4),\n",
    "        object_ids NDARRAY FLOAT32(ANYDIM)\n",
    "    );\n",
    "\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    response = cursor.fetch_all()\n",
    "    \n",
    "    if response.status == '0':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24249d6f-4f71-411c-ba6d-62913bebbc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_video_info(info_path, total_frames):\n",
    "    \"\"\"\n",
    "    Parses a given info json file. total_frames is required to know which entry in the json corresponds to which frame id of video\n",
    "    \n",
    "    Args:\n",
    "        info_path (string) - path to the info file\n",
    "        total_frames (int) - total frames of the current video\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"parsing: {info_path}\")\n",
    "    with open(info_path, 'rb') as json_file:\n",
    "        info_json = json.load(json_file)\n",
    "        \n",
    "    # number of frames for which we have information\n",
    "    num_frames_info = len(info_json)\n",
    "    \n",
    "    # we assume the entries in the frame info are equally spaced\n",
    "    # eg: if there are 100 total frames and 10 entries in info_json, then sample_frequency = 10 or we have info for \n",
    "    # every 10 frames\n",
    "    sample_frequency = total_frames / num_frames_info\n",
    "        \n",
    "        \n",
    "    # attach all info to this object, where key is the frame id\n",
    "    video_info = {}\n",
    "    frame_indices = []\n",
    "\n",
    "    for info in info_json:\n",
    "        frame_index = int(info['frameIndex'])\n",
    "        frame_indices.append(frame_index)\n",
    "        frame_id = int(frame_index * sample_frequency)\n",
    "        video_info[frame_id] = {}\n",
    "        object_labels = []\n",
    "        bounding_boxes = []\n",
    "        object_ids = []\n",
    "\n",
    "        for label in info['labels']:\n",
    "            object_labels.append(label['category'])\n",
    "            bounding_boxes.append([[label['box2d']['x1'], label['box2d']['y1']], [label['box2d']['x2'], label['box2d']['y2']]])\n",
    "            object_ids.append(label['id'])\n",
    "\n",
    "        video_info[frame_id]['labels'] = object_labels\n",
    "        video_info[frame_id]['bboxes'] = bounding_boxes\n",
    "        video_info[frame_id]['ids'] = object_ids\n",
    "        \n",
    "    return video_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a7c2d-a169-4187-9d6b-b745e6c62089",
   "metadata": {},
   "source": [
    "## Utility function to load a single frame along with info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62dba765-d22f-48c6-83c5-fd84f6f6ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_frame(dataset_name, frame, info):\n",
    "    \"\"\"\n",
    "    Takes the path to 1 video and its corresponding json file. \n",
    "    Iterates over each frame of the video and performs an INSERT operation on the table\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (string) - name of the dataset this video belongs to. There should be table existing with this name\n",
    "        frame (ndarray) - frame to be inserted into the table\n",
    "        info (json) - info for this frame\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Not able to get a working query. Experimenting with it in the last cell of this notebook\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dcd533-a5c7-4bd2-a9e8-63a12192a61c",
   "metadata": {},
   "source": [
    "## Utility function to load a video along with its info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62f2c035-0b2f-483d-a39d-69c79060f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(dataset_name, video_path, info_path):\n",
    "    \"\"\"\n",
    "    Takes the path to 1 video and its corresponding json file. \n",
    "    Iterates over each frame of the video and performs an INSERT operation on the table\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (string) - name of the dataset this video belongs to. There should be table existing with this name\n",
    "        video_path (string) - path of the video to be loaded\n",
    "        info_path (string) - path of the json file that contains info about the video\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Loading video: {video_path}\")\n",
    "    \n",
    "    # cap object\n",
    "    video_cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # read video config\n",
    "    width = int(video_cap.get(3))\n",
    "    height = int(video_cap.get(4))\n",
    "    fps = video_cap.get(5)\n",
    "    total_frames = video_cap.get(7)\n",
    "    \n",
    "    # get video info in a parsed format\n",
    "    video_info = parse_video_info(info_path, total_frames)\n",
    "\n",
    "    # set output config\n",
    "    color=(0,255,0)\n",
    "    thickness=3\n",
    "\n",
    "    # How frequent you want to load\n",
    "    sampling_rate = 1 \n",
    "\n",
    "    # keep track of frame index\n",
    "    frame_id = 0\n",
    "\n",
    "    # capture frame by frame\n",
    "    ret, frame = video_cap.read()\n",
    "    \n",
    "    while ret:\n",
    "\n",
    "        # read frame by frame\n",
    "        ret, frame = video_cap.read()\n",
    "        if ret == True:\n",
    "            \n",
    "            # then we have info for this frame\n",
    "            if frame_id in video_info:\n",
    "                for bbox, label in zip(video_info[frame_id]['bboxes'], video_info[frame_id]['labels']):\n",
    "\n",
    "                    x1, y1 = bbox[0]\n",
    "                    x2, y2 = bbox[1]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    frame=cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness) # object bbox\n",
    "                    cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, thickness-1) # object label\n",
    "                    \n",
    "                # TODO: call insert_frame() with the corresponding frame info\n",
    "                #print(f\"insert_frame(dataset_name(string), frame (ndarray), info(json) video_info[frame_id])\")\n",
    "            else:\n",
    "                pass\n",
    "                # TODO call insert_frame() with the empty video info\n",
    "                #print(f\"insert_frame(dataset_name(string), frame (ndarray), info(json) EMPTY)\")\n",
    "                \n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('Frame', frame)\n",
    "\n",
    "            # Press Q on keyboard to  exit\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            frame_id += 1\n",
    "\n",
    "        # Break the loop\n",
    "        else: \n",
    "            break\n",
    "\n",
    "    video_cap.release()\n",
    "    cv2.destroyAllWindows()  \n",
    "    \n",
    "    # return last frame (remove this)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f201321-c36e-4584-93c9-bdd0878c35f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name):\n",
    "    \"\"\"\n",
    "    A folder named dataset_name is expected to be inside datasets. This folder should contain 2 other folders named info and videos\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (string) - name of the dataset\n",
    "        \n",
    "    Returns:\n",
    "        True if all videos have been loaded succesfully\n",
    "        False if there was any error\n",
    "    \"\"\"\n",
    "    \n",
    "    root = \"../\"\n",
    "\n",
    "    # dataset_name must be your folder name\n",
    "    dataset_path = os.path.join(root, 'datasets', dataset_name)\n",
    "    \n",
    "    print(f\"Loading {dataset_name} from the path {dataset_path}\")\n",
    "    \n",
    "    if create_table(dataset_name):\n",
    "        print(f\"Table created successfully for {dataset_name}\")\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    # videos contains the raw videos\n",
    "    videos_path = os.path.join(dataset_path, 'videos')\n",
    "\n",
    "    # info contains a json file corresponding to each video\n",
    "    info_path = os.path.join(dataset_path, 'info')\n",
    "\n",
    "    # Load the paths for all videos and info files\n",
    "    video_files = [os.path.join(videos_path, f) for f in sorted(os.listdir(videos_path))]\n",
    "    info_files = [os.path.join(info_path, f) for f in sorted(os.listdir(info_path))]\n",
    "    \n",
    "    # check that each video under videos has a corresponding json file\n",
    "    for video_file in video_files:\n",
    "        video_name = video_file.split('/')[-1].split('.')[-2]\n",
    "        expected_info_file = os.path.join(dataset_path, 'info', video_name + '.json')\n",
    "        if expected_info_file not in info_files:\n",
    "            print(f\"Each video under videos should have a corresponding info file under info.\")\n",
    "            return False\n",
    "        \n",
    "    dataset_len = len(video_files)\n",
    "    \n",
    "    for video_index in range(dataset_len):\n",
    "        video_path = video_files[video_index]\n",
    "        info_path = info_files[video_index]\n",
    "        \n",
    "        # load this video\n",
    "        load_video(dataset_name, video_path, info_path)\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f670e550-75a7-4614-affc-1e880f308eb8",
   "metadata": {},
   "source": [
    "## Load a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f7aa4ba-608f-4201-b2a3-ae29fdab171f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bdd_test from the path ../datasets/bdd_test\n",
      "Table created successfully for bdd_test\n",
      "Loading video: ../datasets/bdd_test/videos/00a04f65-8c891f94.mp4\n",
      "parsing: ../datasets/bdd_test/info/00a04f65-8c891f94.json\n",
      "Loading video: ../datasets/bdd_test/videos/00a04f65-af2ab984.mp4\n",
      "parsing: ../datasets/bdd_test/info/00a04f65-af2ab984.json\n",
      "Loading video: ../datasets/bdd_test/videos/00a0f008-3c67908e.mp4\n",
      "parsing: ../datasets/bdd_test/info/00a0f008-3c67908e.json\n",
      "Loading video: ../datasets/bdd_test/videos/00a0f008-a315437f.mp4\n",
      "parsing: ../datasets/bdd_test/info/00a0f008-a315437f.json\n",
      "Loading video: ../datasets/bdd_test/videos/00a2e3ca-5c856cde.mp4\n",
      "parsing: ../datasets/bdd_test/info/00a2e3ca-5c856cde.json\n",
      "Loading video: ../datasets/bdd_test/videos/00a2e3ca-62992459.mp4\n",
      "parsing: ../datasets/bdd_test/info/00a2e3ca-62992459.json\n",
      "Loading video: ../datasets/bdd_test/videos/00a2f5b6-d4217a96.mp4\n",
      "parsing: ../datasets/bdd_test/info/00a2f5b6-d4217a96.json\n",
      "Loading video: ../datasets/bdd_test/videos/00a395fe-d60c0b47.mp4\n",
      "parsing: ../datasets/bdd_test/info/00a395fe-d60c0b47.json\n",
      "Loading video: ../datasets/bdd_test/videos/00a820ef-2b98dcf5.mp4\n",
      "parsing: ../datasets/bdd_test/info/00a820ef-2b98dcf5.json\n",
      "Loading video: ../datasets/bdd_test/videos/00a9cd6b-b39be004.mp4\n",
      "parsing: ../datasets/bdd_test/info/00a9cd6b-b39be004.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"bdd_test\"\n",
    "\n",
    "load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76955889-d9fd-46d7-9638-543af99986aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experimenting with frame inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd9f3487-aaa7-4faa-9663-d3bd1659902d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert frame query: INSERT INTO BDD (frame_id, video_id, frame_data, labels, bboxes, object_ids) VALUES (1, 1, [[[33 39 43]\n",
      "  [32 38 42]\n",
      "  [29 35 39]\n",
      "  ...\n",
      "  [24 21 28]\n",
      "  [23 20 27]\n",
      "  [29 26 33]]\n",
      "\n",
      " [[39 45 49]\n",
      "  [38 44 48]\n",
      "  [34 40 44]\n",
      "  ...\n",
      "  [23 20 27]\n",
      "  [24 21 28]\n",
      "  [31 28 35]]\n",
      "\n",
      " [[40 46 50]\n",
      "  [38 44 48]\n",
      "  [34 40 44]\n",
      "  ...\n",
      "  [22 19 26]\n",
      "  [26 23 30]\n",
      "  [37 34 41]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[10 11  6]\n",
      "  [10 11  6]\n",
      "  [10 11  6]\n",
      "  ...\n",
      "  [12 12 12]\n",
      "  [12 12 12]\n",
      "  [16 16 16]]\n",
      "\n",
      " [[14 11  5]\n",
      "  [14 11  5]\n",
      "  [14 11  5]\n",
      "  ...\n",
      "  [13 13 13]\n",
      "  [10 10 10]\n",
      "  [ 9  9  9]]\n",
      "\n",
      " [[20 17 11]\n",
      "  [20 17 11]\n",
      "  [19 16 10]\n",
      "  ...\n",
      "  [16 16 16]\n",
      "  [ 9  9  9]\n",
      "  [ 5  5  5]]], ['car', 'car'], [[[1, 2], [3, 4]], [[1, 2], [3, 4]]], [0, 0]);\n"
     ]
    }
   ],
   "source": [
    "# read a sample frame\n",
    "video_path = '../datasets/bdd_test/videos/00a04f65-8c891f94.mp4'\n",
    "video_cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = video_cap.read()\n",
    "\n",
    "frame_id_ = 1\n",
    "video_id_ = 1\n",
    "frame_data_ = frame\n",
    "labels_ = ['car', 'car']\n",
    "bboxes_ = [[[1, 2], [3, 4]], [[1, 2], [3, 4]]]\n",
    "object_ids_ = [0, 0]\n",
    "\n",
    "insert_frame_query = f\"INSERT INTO BDD (frame_id, video_id, frame_data, labels, bboxes, object_ids) VALUES ({frame_id_}, {video_id_}, {frame_data_}, {labels_}, {bboxes_}, {object_ids_});\"\n",
    "\n",
    "print(f\"insert frame query: {insert_frame_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32923918-1969-4f3f-a2e5-c46638e336d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Object:\n",
      "@status: -1\n",
      "@batch: Batch Object:\n",
      "@dataframe:                      error\n",
      "0  list index out of range\n",
      "@batch_size: 1\n",
      "@identifier_column: id\n",
      "@metrics: None\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(insert_frame_query)\n",
    "response = cursor.fetch_all()\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eva",
   "language": "python",
   "name": "eva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
